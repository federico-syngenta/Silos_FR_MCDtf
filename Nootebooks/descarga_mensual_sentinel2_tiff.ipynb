{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5abb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doc https://documentation.dataspace.copernicus.eu/notebook-samples/sentinelhub/introduction_to_SH_APIs.html\n",
    "#API KEY : https://shapps.dataspace.copernicus.eu/dashboard/#/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b8c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentinelhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c1b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import getpass\n",
    "\n",
    "from sentinelhub import (\n",
    "    SHConfig,\n",
    "    DataCollection,\n",
    "    SentinelHubCatalog,\n",
    "    SentinelHubRequest,\n",
    "    SentinelHubStatistical,\n",
    "    BBox,\n",
    "    bbox_to_dimensions,\n",
    "    CRS,\n",
    "    MimeType,\n",
    "    Geometry,\n",
    ")\n",
    "\n",
    "#from utils import plot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9617e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carga las variables del archivo .env (en el directorio ra√≠z del proyecto)\n",
    "load_dotenv(dotenv_path='../.env')  # Ajusta la ruta si tu notebook est√° en una subcarpeta\n",
    "\n",
    "client_id = os.environ.get('CDSE_CLIENT_ID')\n",
    "client_secret = os.environ.get('CDSE_CLIENT_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4dec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if you have not created a configuration.\n",
    "\n",
    "config = SHConfig()\n",
    "config.sh_client_id = client_id\n",
    "config.sh_client_secret = client_secret\n",
    "config.sh_token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "config.sh_base_url = \"https://sh.dataspace.copernicus.eu\"\n",
    "config.save(\"cdse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd824b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir el √°rea de inter√©s (AOI) con 4 puntos de lat/lon\n",
    "lon_min = -63.95\n",
    "lat_min = -31.75\n",
    "lon_max = -63.75\n",
    "lat_max = -31.60\n",
    "\n",
    "aoi_coords_wgs84 = [lon_min, lat_min, lon_max, lat_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924861c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape at 10 m resolution: (1883, 1677) pixels\n"
     ]
    }
   ],
   "source": [
    "resolution = 10\n",
    "aoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\n",
    "aoi_size = bbox_to_dimensions(aoi_bbox, resolution=resolution)\n",
    "\n",
    "print(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c244fb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentinelhub.api.catalog.SentinelHubCatalog at 0x19ff48eb230>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog = SentinelHubCatalog(config=config)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c14f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of results: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'S2A_MSIL2A_20250719T141111_N0511_R110_T20HMK_20250719T211521.SAFE',\n",
       "  'properties': {'datetime': '2025-07-19T14:21:58.521Z'}},\n",
       " {'id': 'S2A_MSIL2A_20250719T141111_N0511_R110_T20JML_20250719T211521.SAFE',\n",
       "  'properties': {'datetime': '2025-07-19T14:21:44.092Z'}},\n",
       " {'id': 'S2C_MSIL2A_20250717T141111_N0511_R110_T20HMK_20250717T173322.SAFE',\n",
       "  'properties': {'datetime': '2025-07-17T14:22:02.422Z'}},\n",
       " {'id': 'S2C_MSIL2A_20250717T141111_N0511_R110_T20JML_20250717T173322.SAFE',\n",
       "  'properties': {'datetime': '2025-07-17T14:21:47.995Z'}},\n",
       " {'id': 'S2B_MSIL2A_20250712T140709_N0511_R110_T20HMK_20250712T173831.SAFE',\n",
       "  'properties': {'datetime': '2025-07-12T14:21:42.721Z'}},\n",
       " {'id': 'S2B_MSIL2A_20250712T140709_N0511_R110_T20JML_20250712T173831.SAFE',\n",
       "  'properties': {'datetime': '2025-07-12T14:21:28.273Z'}},\n",
       " {'id': 'S2C_MSIL2A_20250707T141111_N0511_R110_T20HMK_20250707T191716.SAFE',\n",
       "  'properties': {'datetime': '2025-07-07T14:22:01.949Z'}},\n",
       " {'id': 'S2C_MSIL2A_20250707T141111_N0511_R110_T20JML_20250707T191716.SAFE',\n",
       "  'properties': {'datetime': '2025-07-07T14:21:47.516Z'}},\n",
       " {'id': 'S2B_MSIL2A_20250702T140709_N0511_R110_T20HMK_20250702T175025.SAFE',\n",
       "  'properties': {'datetime': '2025-07-02T14:21:42.262Z'}},\n",
       " {'id': 'S2B_MSIL2A_20250702T140709_N0511_R110_T20JML_20250702T175025.SAFE',\n",
       "  'properties': {'datetime': '2025-07-02T14:21:27.817Z'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoi_bbox = BBox(bbox=aoi_coords_wgs84, crs=CRS.WGS84)\n",
    "time_interval = \"2025-07-01\", \"2025-07-20\"\n",
    "\n",
    "search_iterator = catalog.search(\n",
    "    DataCollection.SENTINEL2_L2A,\n",
    "    bbox=aoi_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"], \"exclude\": []},\n",
    ")\n",
    "\n",
    "results = list(search_iterator)\n",
    "print(\"Total number of results:\", len(results))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ac9afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DOWNLOADING COMPLETE SENTINEL-2 TILES (PLATFORM FILTERING)\n",
      "============================================================\n",
      "AOI: [-63.95, -31.75, -63.75, -31.6]\n",
      "Date range: 2024-07-01 to 2024-07-20\n",
      "Platform filter: S2A\n",
      "============================================================\n",
      "‚úì Access token obtained successfully\n",
      "üîç Searching for Sentinel-2 products via OData...\n",
      "‚ö†Ô∏è OData returned non-200. Intentando fallback usando ContentDate...\n",
      "‚úì OData returned 4 products (before post-filtering)\n",
      "‚úì After name/content-date post-filter: 4 products\n",
      "\n",
      "[1/4] Processing product: S2A_MSIL2A_20240712T140711_N0510_R110_T20HMK_20240712T213453.SAFE\n",
      "    ‚úì File already exists, skipping download: S2A_MSIL2A_20240712T140711_N0510_R110_T20HMK_20240712T213453.SAFE.zip\n",
      "üì¶ Extracting and processing: S2A_MSIL2A_20240712T140711_N0510_R110_T20HMK_20240712T213453.SAFE.zip\n",
      "    Processing .SAFE: S2A_MSIL2A_20240712T140711_N0510_R110_T20HMK_20240712T213453.SAFE\n",
      "        ‚úó RGB creation error: Deleting processed_tiles\\S2A_MSIL2A_20240712T140711_N0510_R110_T20HMK_20240712T213453_RGB_10m.tiff failed: Permission denied\n",
      "    ‚úó Failed to create RGB composite\n",
      "\n",
      "[2/4] Processing product: S2A_MSIL2A_20240712T140711_N0510_R110_T20JML_20240712T213453.SAFE\n",
      "    ‚úì File already exists, skipping download: S2A_MSIL2A_20240712T140711_N0510_R110_T20JML_20240712T213453.SAFE.zip\n",
      "üì¶ Extracting and processing: S2A_MSIL2A_20240712T140711_N0510_R110_T20JML_20240712T213453.SAFE.zip\n",
      "    Processing .SAFE: S2A_MSIL2A_20240712T140711_N0510_R110_T20JML_20240712T213453.SAFE\n",
      "        ‚úó RGB creation error: Deleting processed_tiles\\S2A_MSIL2A_20240712T140711_N0510_R110_T20JML_20240712T213453_RGB_10m.tiff failed: Permission denied\n",
      "    ‚úó Failed to create RGB composite\n",
      "\n",
      "[3/4] Processing product: S2A_MSIL2A_20240702T140711_N0510_R110_T20HMK_20240702T211349.SAFE\n",
      "    ‚úì File already exists, skipping download: S2A_MSIL2A_20240702T140711_N0510_R110_T20HMK_20240702T211349.SAFE.zip\n",
      "üì¶ Extracting and processing: S2A_MSIL2A_20240702T140711_N0510_R110_T20HMK_20240702T211349.SAFE.zip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 347\u001b[39m\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRaw zips in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDOWNLOAD_DIR.resolve()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[43mdownload_complete_sentinel2_tiles_odata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAOI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPLATFORM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_products\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_PRODUCTS_TO_PROCESS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 331\u001b[39m, in \u001b[36mdownload_complete_sentinel2_tiles_odata\u001b[39m\u001b[34m(aoi, start_date, end_date, platform, max_products)\u001b[39m\n\u001b[32m    329\u001b[39m     failed += \u001b[32m1\u001b[39m\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m processed = \u001b[43mextract_and_process_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m processed:\n\u001b[32m    333\u001b[39m     successful += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 207\u001b[39m, in \u001b[36mextract_and_process_safe\u001b[39m\u001b[34m(zip_file, output_dir)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile.ZipFile(zip_file, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m         \u001b[43mzf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    ‚úó Error extracting zip: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1788\u001b[39m, in \u001b[36mZipFile.extractall\u001b[39m\u001b[34m(self, path, members, pwd)\u001b[39m\n\u001b[32m   1785\u001b[39m     path = os.fspath(path)\n\u001b[32m   1787\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[32m-> \u001b[39m\u001b[32m1788\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1850\u001b[39m, in \u001b[36mZipFile._extract_member\u001b[39m\u001b[34m(self, member, targetpath, pwd)\u001b[39m\n\u001b[32m   1846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[32m   1848\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.open(member, pwd=pwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[32m   1849\u001b[39m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[32m-> \u001b[39m\u001b[32m1850\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1852\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\shutil.py:203\u001b[39m, in \u001b[36mcopyfileobj\u001b[39m\u001b[34m(fsrc, fdst, length)\u001b[39m\n\u001b[32m    201\u001b[39m fsrc_read = fsrc.read\n\u001b[32m    202\u001b[39m fdst_write = fdst.write\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buf := \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    204\u001b[39m     fdst_write(buf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1015\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m-> \u001b[39m\u001b[32m1015\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m   1017\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1085\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1083\u001b[39m         data += \u001b[38;5;28mself\u001b[39m._read2(n - \u001b[38;5;28mlen\u001b[39m(data))\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compress_type == ZIP_STORED:\n\u001b[32m   1088\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = \u001b[38;5;28mself\u001b[39m._compress_left <= \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1115\u001b[39m, in \u001b[36mZipExtFile._read2\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1112\u001b[39m n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m   1113\u001b[39m n = \u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mself\u001b[39m._compress_left)\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28mself\u001b[39m._compress_left -= \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:834\u001b[39m, in \u001b[36m_SharedFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    830\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt read from the ZIP file while there \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    831\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis an open writing handle on it. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mClose the writing handle before trying to read.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    833\u001b[39m \u001b[38;5;28mself\u001b[39m._file.seek(\u001b[38;5;28mself\u001b[39m._pos)\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[38;5;28mself\u001b[39m._pos = \u001b[38;5;28mself\u001b[39m._file.tell()\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Descarga robusta de tiles completos Sentinel-2 (L2A) desde Copernicus Data Space (ODATA).\n",
    "Incluye filtro por plataforma (ej: 'S2A') + post-filtrado por fecha de sensado extra√≠da del NAME.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date\n",
    "import requests\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------\n",
    "# CONFIGURACI√ìN (modifica aqu√≠)\n",
    "# ----------------------\n",
    "CLIENT_ID = os.environ.get(\"CDSE_CLIENT_ID\", client_id)\n",
    "CLIENT_SECRET = os.environ.get(\"CDSE_CLIENT_SECRET\", client_secret)\n",
    "\n",
    "AOI = [-63.95, -31.75, -63.75, -31.6]\n",
    "START_DATE = \"2024-07-01\"\n",
    "END_DATE   = \"2024-07-20\"\n",
    "MAX_CLOUD_COVER = 20\n",
    "MAX_PRODUCTS_TO_PROCESS = 10\n",
    "DOWNLOAD_DIR = Path(\"sentinel2_complete_tiles\")\n",
    "PROCESSED_DIR = Path(\"processed_tiles\")\n",
    "TOP_N = 200\n",
    "\n",
    "# aqu√≠ eleg√≠s la plataforma: \"S2A\", \"S2B\", \"S2C\" o None para cualquiera\n",
    "PLATFORM = \"S2A\"\n",
    "# ----------------------\n",
    "\n",
    "def get_cdse_access_token(client_id=CLIENT_ID, client_secret=CLIENT_SECRET):\n",
    "    token_url = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    }\n",
    "    resp = requests.post(token_url, data=data, timeout=30)\n",
    "    if resp.status_code == 200:\n",
    "        print(\"‚úì Access token obtained successfully\")\n",
    "        return resp.json().get('access_token')\n",
    "    else:\n",
    "        print(f\"‚úó Failed to get access token: {resp.status_code}\")\n",
    "        print(resp.text)\n",
    "        return None\n",
    "\n",
    "def _parse_sensing_datetime_from_name(name):\n",
    "    m = re.search(r'_(\\d{8}T\\d{6})_', name)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return datetime.strptime(m.group(1), \"%Y%m%dT%H%M%S\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_odata_query(aoi, start_date, end_date, platform=None, attempt_sensing_filter=True, top=TOP_N):\n",
    "    lon_min, lat_min, lon_max, lat_max = aoi\n",
    "    wkt_polygon = f\"POLYGON(({lon_min} {lat_min},{lon_max} {lat_min},{lon_max} {lat_max},{lon_min} {lat_max},{lon_min} {lat_min}))\"\n",
    "    base_url = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products\"\n",
    "\n",
    "    sensing_field_candidates = [\"SensingTime\", \"SensingStart\", \"SensingStartDate\", \"SensingStartDateTime\"]\n",
    "    content_filter = f\"ContentDate/Start ge {start_date}T00:00:00.000Z and ContentDate/Start le {end_date}T23:59:59.999Z\"\n",
    "\n",
    "    filters = [\n",
    "        \"Collection/Name eq 'SENTINEL-2'\",\n",
    "        \"contains(Name,'MSIL2A')\",\n",
    "        f\"OData.CSC.Intersects(area=geography'SRID=4326;{wkt_polygon}')\",\n",
    "    ]\n",
    "\n",
    "    # filtro por plataforma (ej: startswith(Name,'S2A_'))\n",
    "    if platform:\n",
    "        # usamos startswith para reducir resultados; si el servicio no soporta startswith, el servidor podr√≠a retornar error o ignorarlo\n",
    "        filters.append(f\"startswith(Name,'{platform}_') eq true\")\n",
    "\n",
    "    if attempt_sensing_filter:\n",
    "        sensing_candidate = sensing_field_candidates[0]\n",
    "        sensing_filter = f\"{sensing_candidate} ge {start_date}T00:00:00.000Z and {sensing_candidate} le {end_date}T23:59:59.999Z\"\n",
    "        filters.append(sensing_filter)\n",
    "    else:\n",
    "        filters.append(content_filter)\n",
    "\n",
    "    filter_string = \" and \".join(filters)\n",
    "    url = f\"{base_url}?$filter={filter_string}&$orderby=ContentDate/Start desc&$top={top}\"\n",
    "    return url\n",
    "\n",
    "def search_sentinel2_products_odata(aoi, start_date, end_date, access_token=None, platform=None, top=TOP_N):\n",
    "    print(\"üîç Searching for Sentinel-2 products via OData...\")\n",
    "    url = build_odata_query(aoi, start_date, end_date, platform=platform, attempt_sensing_filter=True, top=top)\n",
    "    headers = {}\n",
    "    if access_token:\n",
    "        headers['Authorization'] = f'Bearer {access_token}'\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=60)\n",
    "    except Exception as e:\n",
    "        print(\"‚úó Error contacting OData endpoint:\", e)\n",
    "        return []\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        print(\"‚ö†Ô∏è OData returned non-200. Intentando fallback usando ContentDate...\")\n",
    "        url = build_odata_query(aoi, start_date, end_date, platform=platform, attempt_sensing_filter=False, top=top)\n",
    "        try:\n",
    "            resp = requests.get(url, headers=headers, timeout=60)\n",
    "        except Exception as e:\n",
    "            print(\"‚úó Fallback request failed:\", e)\n",
    "            return []\n",
    "        if resp.status_code != 200:\n",
    "            print(\"‚úó Fallback OData also failed:\", resp.status_code)\n",
    "            print(resp.text)\n",
    "            return []\n",
    "\n",
    "    data = resp.json()\n",
    "    products = data.get('value', [])\n",
    "    print(f\"‚úì OData returned {len(products)} products (before post-filtering)\")\n",
    "\n",
    "    # POST-FILTER por fecha de sensado y plataforma (seguro)\n",
    "    start_dt = datetime.fromisoformat(start_date).date()\n",
    "    end_dt = datetime.fromisoformat(end_date).date()\n",
    "\n",
    "    final_products = []\n",
    "    for p in products:\n",
    "        name = p.get('Name', '')\n",
    "        # 1) comprobar plataforma v√≠a nombre (si PLATFORM fue pedido)\n",
    "        if platform and not name.startswith(f\"{platform}_\"):\n",
    "            # si no coincide, omitir\n",
    "            continue\n",
    "        # 2) extraer fecha de sensado desde name\n",
    "        sensing_dt = _parse_sensing_datetime_from_name(name)\n",
    "        if sensing_dt:\n",
    "            if start_dt <= sensing_dt.date() <= end_dt:\n",
    "                final_products.append(p)\n",
    "        else:\n",
    "            # fallback a ContentDate\n",
    "            cd = p.get('ContentDate', {})\n",
    "            cd_start = cd.get('Start')\n",
    "            if cd_start:\n",
    "                try:\n",
    "                    cd_dt = datetime.fromisoformat(cd_start.replace('Z','')).date()\n",
    "                    if start_dt <= cd_dt <= end_dt:\n",
    "                        final_products.append(p)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    print(f\"‚úì After name/content-date post-filter: {len(final_products)} products\")\n",
    "    return final_products\n",
    "\n",
    "def download_sentinel2_product(product_info, access_token, download_dir=DOWNLOAD_DIR, chunk_size=16*1024):\n",
    "    product_id = product_info['Id']\n",
    "    product_name = product_info['Name']\n",
    "    download_dir = Path(download_dir)\n",
    "    download_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    download_url = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
    "    zip_filename = download_dir / f\"{product_name}.zip\"\n",
    "    headers = {}\n",
    "    if access_token:\n",
    "        headers['Authorization'] = f'Bearer {access_token}'\n",
    "\n",
    "    if zip_filename.exists():\n",
    "        print(f\"    ‚úì File already exists, skipping download: {zip_filename.name}\")\n",
    "        return str(zip_filename)\n",
    "\n",
    "    print(f\"üì• Downloading: {product_name}\")\n",
    "    try:\n",
    "        with requests.get(download_url, headers=headers, stream=True, timeout=120) as r:\n",
    "            if r.status_code != 200:\n",
    "                print(f\"    ‚úó Download failed: {r.status_code}\")\n",
    "                return None\n",
    "            total = int(r.headers.get('content-length', 0))\n",
    "            downloaded = 0\n",
    "            with open(zip_filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        if total:\n",
    "                            if downloaded % (10*1024*1024) < chunk_size:\n",
    "                                percent = downloaded / total * 100\n",
    "                                print(f\"    Progress: {percent:.1f}% ({downloaded/1024/1024:.1f} MB)\")\n",
    "            print(f\"    ‚úì Download completed: {downloaded/1024/1024:.1f} MB\")\n",
    "            return str(zip_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Error downloading: {e}\")\n",
    "        if zip_filename.exists():\n",
    "            try:\n",
    "                zip_filename.unlink()\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "def extract_and_process_safe(zip_file, output_dir=PROCESSED_DIR):\n",
    "    zip_file = Path(zip_file)\n",
    "    print(f\"üì¶ Extracting and processing: {zip_file.name}\")\n",
    "    extract_dir = zip_file.with_suffix('')\n",
    "    output_dir = Path(output_dir)\n",
    "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zf:\n",
    "            zf.extractall(extract_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Error extracting zip: {e}\")\n",
    "        return None\n",
    "\n",
    "    safe_dirs = list(extract_dir.glob(\"*.SAFE\"))\n",
    "    if not safe_dirs:\n",
    "        safe_dirs = list(extract_dir.rglob(\"*.SAFE\"))\n",
    "    if not safe_dirs:\n",
    "        print(\"    ‚úó No .SAFE directory found\")\n",
    "        return None\n",
    "\n",
    "    safe_dir = safe_dirs[0]\n",
    "    safe_name = safe_dir.name\n",
    "    print(f\"    Processing .SAFE: {safe_name}\")\n",
    "\n",
    "    band_pattern = str(safe_dir / \"GRANULE\" / \"*\" / \"IMG_DATA\" / \"R10m\" / \"*_B0?_10m.jp2\")\n",
    "    band_files = glob.glob(band_pattern)\n",
    "    if not band_files:\n",
    "        band_files = list(safe_dir.rglob(\"*_B0?_10m.jp2\"))\n",
    "\n",
    "    rgb_bands = {}\n",
    "    for bf in band_files:\n",
    "        if '_B02_' in bf:\n",
    "            rgb_bands['B02'] = bf\n",
    "        elif '_B03_' in bf:\n",
    "            rgb_bands['B03'] = bf\n",
    "        elif '_B04_' in bf:\n",
    "            rgb_bands['B04'] = bf\n",
    "\n",
    "    if len(rgb_bands) != 3:\n",
    "        print(f\"    ‚úó Missing RGB bands, found: {list(rgb_bands.keys())}\")\n",
    "        return None\n",
    "\n",
    "    output_filename = f\"{safe_name.replace('.SAFE','')}_RGB_10m.tiff\"\n",
    "    output_path = output_dir / output_filename\n",
    "\n",
    "    success = create_rgb_composite(rgb_bands, output_path, safe_name)\n",
    "    if success:\n",
    "        print(f\"    ‚úì RGB composite created: {output_filename}\")\n",
    "        return str(output_path)\n",
    "    else:\n",
    "        print(\"    ‚úó Failed to create RGB composite\")\n",
    "        return None\n",
    "\n",
    "def create_rgb_composite(rgb_bands, output_path, safe_name):\n",
    "    try:\n",
    "        bands_data = {}\n",
    "        transform = None\n",
    "        crs = None\n",
    "        height = width = None\n",
    "\n",
    "        for band_key in ['B04', 'B03', 'B02']:\n",
    "            band_file = rgb_bands.get(band_key)\n",
    "            with rasterio.open(band_file) as src:\n",
    "                arr = src.read(1)\n",
    "                bands_data[band_key] = arr\n",
    "                if transform is None:\n",
    "                    transform = src.transform\n",
    "                    crs = src.crs\n",
    "                    height, width = src.shape\n",
    "\n",
    "        rgb_array = np.stack([bands_data['B04'], bands_data['B03'], bands_data['B02']], axis=0)\n",
    "        rgb_normalized = np.clip(rgb_array * 3.5, 0, 10000).astype(np.uint16)\n",
    "\n",
    "        output_path = Path(output_path)\n",
    "        with rasterio.open(\n",
    "            output_path, 'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=3,\n",
    "            dtype='uint16',\n",
    "            crs=crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512\n",
    "        ) as dst:\n",
    "            dst.write(rgb_normalized)\n",
    "            dst.update_tags(\n",
    "                PRODUCT_NAME=safe_name,\n",
    "                BANDS='RGB (B04,B03,B02)',\n",
    "                RESOLUTION='10m',\n",
    "                PRODUCT_TYPE='SENTINEL2_L2A_COMPLETE_TILE_RGB'\n",
    "            )\n",
    "\n",
    "        size_mb = output_path.stat().st_size / (1024*1024)\n",
    "        print(f\"        ‚úì RGB composite saved ({size_mb:.1f} MB)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"        ‚úó RGB creation error: {e}\")\n",
    "        return False\n",
    "\n",
    "def download_complete_sentinel2_tiles_odata(aoi, start_date, end_date, platform=None, max_products=MAX_PRODUCTS_TO_PROCESS):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNLOADING COMPLETE SENTINEL-2 TILES (PLATFORM FILTERING)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"AOI: {aoi}\")\n",
    "    print(f\"Date range: {start_date} to {end_date}\")\n",
    "    print(f\"Platform filter: {platform}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    token = get_cdse_access_token()\n",
    "    if not token:\n",
    "        print(\"‚úó No access token. Aborting.\")\n",
    "        return\n",
    "\n",
    "    products = search_sentinel2_products_odata(aoi, start_date, end_date, access_token=token, platform=platform, top=TOP_N)\n",
    "    if not products:\n",
    "        print(\"No products found after post-filter.\")\n",
    "        return\n",
    "\n",
    "    if max_products:\n",
    "        products = products[:max_products]\n",
    "\n",
    "    successful = failed = 0\n",
    "    for i, p in enumerate(products, 1):\n",
    "        print(f\"\\n[{i}/{len(products)}] Processing product: {p.get('Name')}\")\n",
    "        zipf = download_sentinel2_product(p, token)\n",
    "        if not zipf:\n",
    "            failed += 1\n",
    "            continue\n",
    "        processed = extract_and_process_safe(zipf)\n",
    "        if processed:\n",
    "            successful += 1\n",
    "            print(f\"‚úì Successfully processed: {Path(processed).name}\")\n",
    "        else:\n",
    "            failed += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNLOAD FINISHED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"‚úì Successfully processed: {successful}\")\n",
    "    print(f\"‚úó Failed: {failed}\")\n",
    "    print(f\"Processed files in: {PROCESSED_DIR.resolve()}\")\n",
    "    print(f\"Raw zips in: {DOWNLOAD_DIR.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_complete_sentinel2_tiles_odata(AOI, START_DATE, END_DATE, platform=PLATFORM, max_products=MAX_PRODUCTS_TO_PROCESS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a05ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
